{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic image formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import holoviews.operation.datashader as hd\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase history simulation\n",
    "The goal of this is to simulate what the received demodulated signal for a SAR system is. Recall from the previous notebook that the zero IF signal we sample is given by:\n",
    "$$x_{IF}(t, \\tau) = Ae^{\\frac{-4j\\pi R(\\tau)}{\\lambda}}e^{j\\pi \\gamma (t-\\frac{2R(\\tau)}{c})^2}$$\n",
    "To take digitization into consideration then we will convert continuous time into discrete time by sampling the signal which means we can re-write this as:\n",
    "\n",
    "$$x_{IF}(n, m) = Ae^{\\frac{-4j\\pi R[m]}{\\lambda}}e^{j\\pi \\gamma (n-f_s\\frac{2R[m]}{c})^2}$$\n",
    "We'll use the following definition of our system for this simulation\n",
    "## System parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.constants import c as speed_of_light\n",
    "# Geometry \n",
    "arp_poly=np.array([\n",
    "    [4800897.883632624, 57.036013951381584], [2752862.8001471036, -4.058634127391252], [3180199.1684093135, -82.03914066808467]\n",
    "])\n",
    "p_scp=np.array([4787610.688267582, 2764128.319646417,  3170373.7353836414])\n",
    "\n",
    "num_pulses = 2000 # number of pulses we transmit\n",
    "prf = 4000 # pulse repition frequency in Hz\n",
    "bandwidth = 100e6 # trasnmit RF bandwidth in Hz\n",
    "tx_pulse_len = 1e-05 # Duration of the pulse we send in seconds\n",
    "t_start = 0.0 # time when we start transmitting pulses in seconds\n",
    "t_end = 0.4998734257422694 # time of last pulse we sent in seconds\n",
    "chirp_rate = bandwidth / tx_pulse_len # chirp rate in Hz/s\n",
    "fc = 10e9 # center frequency of the system in Hz\n",
    "wavelen = speed_of_light / fc # wavelenght of the center frequecny in meters\n",
    "rx_window_factor = 3 # multiplier on the pulse length for how long we listen\n",
    "rx_nyquist_factor = 1.25 # how much over nyquist rate we oversample\n",
    "sampling_rate = 2 * bandwidth * rx_nyquist_factor # ADC sampling rate in Hz \n",
    "sampling_period = 1 / sampling_rate # ADC sampling period in seconds\n",
    "rx_window_duration = rx_window_factor * tx_pulse_len # Duration of the receive window in seconds\n",
    "tx_times = np.arange(0, t_end, 1/prf) # Array of times we send pulses in seconds\n",
    "t_adc = np.arange(0, rx_window_duration, sampling_period) # ADC sampling times in seconds\n",
    "t_adc -= t_adc.mean()\n",
    "num_samples = t_adc.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene definition\n",
    "To define a scene (scatterers) to image we'll define them in the slant plane coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.polynomial.polynomial as npp\n",
    "def slant_plane_to_ecef(p_arp_ecef, v_arp_ecef, p_grp_ecef):\n",
    "    x = p_arp_ecef - p_grp_ecef\n",
    "    slt_rg = np.linalg.norm(x, axis=-1)\n",
    "    u_x = x / slt_rg\n",
    "    z = np.cross(u_x, v_arp_ecef, axisa=-1, axisb=-1)\n",
    "\n",
    "    look = 1\n",
    "    u_z = np.expand_dims(look, axis=-1) * (z / (np.linalg.norm(z, axis=-1)))\n",
    "    u_y = np.cross(u_z, u_x, axisa=-1, axisb=-1)\n",
    "    slant_to_ecef = np.stack((u_x, u_y, u_z), axis=-1)\n",
    "    return slant_to_ecef\n",
    "\n",
    "coa_time = (t_end - t_start) / 2 \n",
    "p_coa = npp.polyval(coa_time, arp_poly.T).T\n",
    "v_coa = npp.polyval(coa_time, npp.polyder(arp_poly.T)).T\n",
    "sp_2_ecef = slant_plane_to_ecef(p_coa, v_coa, p_scp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# points_sp = np.stack([\n",
    "#     np.array([-1000, -500, 0]),\n",
    "#     np.array([-400, 400, 0]),\n",
    "#     np.array([0, 0, 0]),\n",
    "#     np.array([300, 300, 0]),\n",
    "#     np.array([600, -600, 0]),\n",
    "# ])\n",
    "points_sp = np.stack([\n",
    "    np.array([400, 0, 0]),\n",
    "])\n",
    "plt.figure()\n",
    "plt.plot(points_sp[:, 1], points_sp[:, 0], 'o')\n",
    "plt.xlabel('Slant plane y (meters) (azimuth direction)')\n",
    "plt.ylabel('Slant plane x (meters) (range direction)')\n",
    "plt.title('Slant plane point locations')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll convert the slant plane positions to ECEF so we can use them in the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = sp_2_ecef @ points_sp.T\n",
    "points_ecef = rotation.T + p_scp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "Now we'll simulate the signal the radar receives over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as npp\n",
    "from scipy.constants import c as speed_of_light\n",
    "targets = [points_ecef[ii,:].flatten() for ii in range(points_ecef.shape[0])]\n",
    "phase_history_per_target = np.zeros((len(targets), num_pulses, num_samples), dtype=np.complex128)\n",
    "\n",
    "def lfm(samp_time):\n",
    "    phase = np.pi * chirp_rate * samp_time * samp_time\n",
    "    half_dur = 0.5 * tx_pulse_len\n",
    "    t_max, t_min = half_dur, -half_dur\n",
    "\n",
    "    mag = np.logical_and(\n",
    "        np.less_equal(samp_time, t_max),\n",
    "        np.greater_equal(samp_time, t_min)\n",
    "    ).astype(float)\n",
    "\n",
    "    return mag * (np.cos(phase) + 1j * np.sin(phase))\n",
    "\n",
    "for i_tgt, tgt_pos in enumerate(targets):\n",
    "    for i_pulse in range(num_pulses):\n",
    "        # Evaluate ARP/GRP poly\n",
    "        arp_pos = npp.polyval(tx_times[i_pulse], arp_poly.T).T\n",
    "        # TODO: Use GRP poly for scan\n",
    "        grp_pos = p_scp\n",
    "\n",
    "        # Compute distance from the ARP to SCP\n",
    "        grp_distance = np.linalg.norm(grp_pos - arp_pos)\n",
    "\n",
    "        # grp_time_delay is the time delay from the ARP to the GRP\n",
    "        grp_time_delay = 2 * grp_distance / speed_of_light\n",
    "        \n",
    "        # compute distance (time delay) from the arp to the target\n",
    "        monostatic_distance = 2 * np.linalg.norm(tgt_pos - arp_pos)\n",
    "\n",
    "        # Using the monostatic approximation we will receive the pulse rx_time\n",
    "        # past tx_time\n",
    "        rx_time = monostatic_distance / speed_of_light\n",
    "\n",
    "        # Compute slow time term\n",
    "        slow_time_term = np.exp(-4.0j * np.pi * monostatic_distance / wavelen)\n",
    "\n",
    "        # Here we want the receive times relative to the delay to the scene center point\n",
    "        # We want to do this so that after motion compensation a target at the mocomp point will show up \n",
    "        # at the center of the receive window.  Here we choose the mocomp point to be the scp (grp)\n",
    "        t_delay = rx_time - grp_time_delay\n",
    "\n",
    "        # Center the ADC around the time delay to the target.  We will clip this to the receive window\n",
    "        # in the lfm function. i,e) if a time delay is outside of the receive window the response will\n",
    "        # be all 0s\n",
    "        t_fast = t_adc - t_delay\n",
    "\n",
    "        # Compute fast time term.  \n",
    "        fast_time_term = lfm(t_fast)\n",
    "\n",
    "        # couple slow time term and fast time term\n",
    "        phase_history_per_target[i_tgt, i_pulse, :] = slow_time_term * fast_time_term \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Let's look at what the phase history looks like for each target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_histories = [\n",
    "    hd.rasterize(\n",
    "        hv.Image(\n",
    "            np.real(phase_history_per_target[ii, :, :]),\n",
    "            bounds=(0, 0, num_samples, num_pulses),\n",
    "        ).opts(\n",
    "            width=400,\n",
    "            height=400,\n",
    "            cmap='gray',\n",
    "            title=f'Target Slant Plane Location {points_sp[ii, 0]}, {points_sp[ii, 1]}',\n",
    "            xlabel='Fast time sample',\n",
    "            ylabel='Slow time sample',\n",
    "        )\n",
    "    )\n",
    "    for ii in range(len(targets))\n",
    "]\n",
    "layout = hv.Layout(phase_histories).cols(2 if len(targets) >= 2 else 1)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_histories = [\n",
    "    hd.rasterize(\n",
    "        hv.Image(\n",
    "            np.unwrap(np.angle(phase_history_per_target[ii, :, :])),\n",
    "            bounds=(0, 0, num_samples, num_pulses),\n",
    "        ).opts(\n",
    "            width=400,\n",
    "            height=400,\n",
    "            # cmap='gray',\n",
    "            title=f'Target Slant Plane Location {points_sp[ii, 0]}, {points_sp[ii, 1]}',\n",
    "            xlabel='Fast time sample',\n",
    "            ylabel='Slow time sample',\n",
    "            colorbar=True,\n",
    "        )\n",
    "    )\n",
    "    for ii in range(len(targets))\n",
    "]\n",
    "layout = hv.Layout(phase_histories).cols(2 if len(targets) >= 2 else 1)\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse returns in the receive window\n",
    "Let's examine what the return for a single pulse for each target looks like in the receive window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_returns = [\n",
    "    hv.Curve(\n",
    "        np.abs(phase_history_per_target[ii, 0, :]),\n",
    "        label=f'Target sp_x location {points_sp[ii, 0]}'\n",
    "    ).opts(\n",
    "        xlabel='fast time index',\n",
    "        title='Receive Window for single pulse',\n",
    "        show_grid=True,\n",
    "    ) for ii in range(len(targets))\n",
    "]\n",
    "hv.Overlay(target_returns).opts(width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal we sample is actually the superposition of all scatterers in the scene.  This means we dont get a phase history per point but rather the phase history of the combination of **all** points.  This means we need to add all the phase histories together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_history = phase_history_per_target.sum(axis=0)\n",
    "print(phase_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.rasterize(\n",
    "    hv.Image(\n",
    "        np.real(phase_history),\n",
    "        bounds=(0, 0, num_samples, num_pulses)\n",
    "    ).opts(\n",
    "        width=600,\n",
    "        height=600,\n",
    "        cmap='gray'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic image formation\n",
    "Our goal is to take the data and form an estimate of the imaged scene.  This estimate is the SAR image.  The first two steps we'll do is \n",
    "1. Resolve range\n",
    "2. Compensate for our relative motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image formation step one: Range matched filter\n",
    "We covered matched filtering already.  Here we construct the matched filter based off of the waveform function $h(t)$.  This step is so for each pulse we know distance to our objects.  \n",
    "\n",
    "The goal of this is to determine range to all points in the scene "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_waveform = lfm(t_adc)\n",
    "matched_filter = np.conj(ref_waveform[::-1])\n",
    "matched_filter_freq = np.fft.fftshift(np.fft.fft(matched_filter))\n",
    "range_dispersed = np.fft.fftshift(np.fft.fft(phase_history, axis=1), axes=1)\n",
    "range_matched_filtered = range_dispersed * matched_filter_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of convolution here we matched filtered by multiplying in the frequency domain. We can take a FFT of this data to take it back to the compressed domain.  We should expect to see range resolved which means we will see a spike in range for each target which spans all of azimuth because we have not figured out point locations in azimuth yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_compmressed = np.fft.ifftshift(np.fft.ifft(range_matched_filtered, axis=1), axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.rasterize(\n",
    "    hv.Image(\n",
    "        np.log10(\n",
    "            np.abs(range_compmressed)\n",
    "        ),\n",
    "        bounds=(0, 0, num_samples, num_pulses),\n",
    "    ).opts(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        cmap='gray',\n",
    "        xlabel='Range (Near Range <--> Far Range)',\n",
    "        ylabel='Pulses',\n",
    "        title='Range compressed'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step two: Azimuth Matched filter (motion compensation)\n",
    "\n",
    "Motion compensation is the undoing of unwanted signal phase induced on the image focal point, known as the Scene Center Point (SCP). In the \n",
    "compressed domain, the SCP signal return should compress to a sinc-like function at DC (zero frequency) so that the center imaging point displays at the center of the image.\n",
    "\n",
    "To compress the SCP to a single sinc-like function at the image center in the compressed domain, the SCP signal return must be a constant-phase rect \n",
    "function in the frequency domain.  \n",
    "\n",
    "Motion compensation has two components:\n",
    "* Along slow-time, the motion of the transmitter and receiver platforms induce a phase modulation.\n",
    "* Along fast-time there will be induced linear phase if the receiver sampling window does not center on the SCP return pulse.\n",
    "    - I do not model this here\n",
    "\n",
    "Overall, the goal of mocomp is to remove the fast-time and slow-time modulation induced upon the SCP return. \n",
    "\n",
    "### Derivation\n",
    "Recall our signal model for the sampled signal is \n",
    "$$x_{IF}(n, m) = Ae^{\\frac{-4j\\pi R[m]}{\\lambda}}e^{j\\pi \\gamma (n-n_{fast}[m])^2}$$\n",
    "Let $e^{j\\pi \\gamma (n-n_{fast}[m])^2} = h(n - n_{fast}[m])$ which means we can rewrite this as\n",
    "$$x_{IF}(n, m) = Ah(n - n_{fast}[m])e^{\\frac{-4j\\pi R[m]}{\\lambda}}$$\n",
    "\n",
    "Lastly, we will re-write the aximuth term back in terms of time delays instead of range:\n",
    "$$x_{IF}(n, m) = Ah(n - n_{fast}[m])e^{-j\\omega \\tau[m]}$$\n",
    "\n",
    "The signal sampled along slow time is in the fourier domain already, so to convert fast time into the frequency domain we'll take the fourier transform\n",
    "$$\\mathcal{F}(x_{IF}(n, m)) = H(\\omega)e^{-j\\omega [n]n_{fast}[m]}e^{-j\\omega \\tau[m]}$$\n",
    "Note that $\\omega[n]$ is a function of the fast time sample $n$.  \n",
    "\n",
    "The goal of motion comensation is to remove these unwanted phase terms to recover exactly $H(\\omega)$ for the scene center point  \n",
    "\n",
    "### Scene center point model\n",
    "\n",
    "Let's assume that we are imaging a single point positioned at the scene center point.  The pulse will be transmitted at time $t_{tx}$, and be received a time later at $t_{rx}$.  The receiver window will then center on $t_{rx}$.  This means that the sample that the SCP return shows up will be at\n",
    "$$n_{scp} = f_s (\\tau_{scp} - t_{rx})$$\n",
    "Where $\\tau_{scp}$ is the two way time delay from the transmitter to the SCP back to the receiver.  \n",
    "\n",
    "This means for a single point scatterer at the SCP the dispersed (frequency domain) SAR signal can be written as:\n",
    "$$X_{IF}(n, m) = H(\\omega)e^{-j\\omega [n]n_{scp}[m]}e^{-j\\omega \\tau_{scp}[m]}$$  \n",
    "\n",
    "We want to remove these unwanted phase terms for the SCP so to do that we will form two corrections; one for Doppler and one for Range.  Note: to undo these terms the corrections will just be the complex conjugate of the unwanted terms  \n",
    "\n",
    "**Doppler correction**:  \n",
    "This term will undo the slow time modulation which changes from pulse to pulse due to our relative motion between the ARP and the SCP.  This makes it so that the relative doppler frequecny for the SCP will be 0 Hz causing it to show up at the center of the image in azimuth \n",
    "$$C_{d} = e^{j\\omega \\tau_{scp}[m]}$$\n",
    "**Range Correction**:  \n",
    "The linear phase term across phase time will cause a sample shift in the compressed domain.  We want the SCP range to show up at DC in the image, so to do that we will undo this linear phase ramp.  This compensates for in general when your receive window is not perfectly center on your scene center point.  \n",
    "$$C_{r} = e^{j\\omega [n]n_{scp}[m]}$$\n",
    "\n",
    "**REMEMBER I DID NOT MODEL THIS IN THIS NOTEBOOK SO I WILL OMIT THIS CORRECTION**\n",
    "\n",
    "Applying these two corrections we see the dispersed signal after mocomp for a single point scatterer at the SCP is given by:\n",
    "$$X_{IF}(n, m) = (H(\\omega)e^{-j\\omega [n]n_{scp}[m]}e^{-j\\omega \\tau_{scp}[m]})(e^{j\\omega \\tau_{scp}[m]})( e^{j\\omega [n]n_{scp}[m]})$$\n",
    "$$X_{IF}(n, m) = H(\\omega)$$\n",
    "For the SCP point now all slow time modulations are removed.  \n",
    "\n",
    "### Post mocomp for point scatterer not at scene center point\n",
    "\n",
    "$$X_{IF}(n, m) = H(\\omega)e^{-j\\omega [n](n_{fast}[m] - n_{scp}[m])}e^{-j\\omega(\\tau[m] -  \\tau_{scp}[m])}$$\n",
    "\n",
    "This will make the signal we sample contain relative doppler frequency to the SCP for each point in the scene  \n",
    "\n",
    "# Visualizing what mocomp does\n",
    "Let's examine what this looks like for the points we simulated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arp_pos = npp.polyval(tx_times, arp_poly.T).T\n",
    "scp_slant_range = np.linalg.norm(grp_pos - arp_pos, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will effectively be referencing all of our distances to each point over slow time to the distance to the SCP over slow time.  Let's compute that compensated distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compensated_distance = []\n",
    "for tgt_pos in targets:\n",
    "    distance_to_target = np.linalg.norm(tgt_pos - arp_pos, axis=-1)\n",
    "    compensated_distance.append(distance_to_target - scp_slant_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the compensated distance looks like for each point scatterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [\n",
    "    hv.Curve(\n",
    "        distance,\n",
    "    ).opts(\n",
    "        width=400,\n",
    "        height=400,\n",
    "        title=f'Target Slant Plane Location {points_sp[ii, 0]}, {points_sp[ii, 1]}',\n",
    "        show_grid=True,\n",
    "        xlabel='Pulse Index',\n",
    "        ylabel='Compensated distance (m)'\n",
    "    )\n",
    "    for ii, distance in enumerate(compensated_distance)\n",
    "]\n",
    "layout = hv.Layout(distances).cols(2 if len(targets) >= 2 else 1).opts(shared_axes=False)\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few interesting observations (recall that the distance to a point scatterer is embedded as a phase term in our singal model)\n",
    "* The comesated distance for the SCP is 0 over slow time\n",
    "* For each point that is offset in azimuth there is a linear relative distance to the SCP over slow time\n",
    "    - This means each point target that is offset in azimuth will have a linear phase term\n",
    " \n",
    "Recall that the derivative of phase is frequency.  This means that after mocomp the linear phase ramp corresponse to an azimuth frequency that uniquely encodes the azimuth position of a point relative to the SCP!  This is how we determine spatially where a point is in azimuth after resolving range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing motion compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_delay = 2 * scp_slant_range / speed_of_light\n",
    "correction = 2 * np.pi * fc * scp_delay\n",
    "cphd = range_matched_filtered * np.exp(1j * correction[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step three: form image\n",
    "At this point we have determined range and a point's spatial location meaning that we have formed an estimate of the fourier transform of the reflectivity function of our scene.  To form the image we can take a FFT of the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.fft.ifftshift(np.fft.ifft2(cphd), axes=(0, 1))\n",
    "img_with_noise = img + 1/np.sqrt(2) * (np.random.randn(num_pulses, num_samples) + 1j*np.random.randn(num_pulses, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_db = np.log10(np.abs(img))\n",
    "lims = np.percentile(img_db.flatten(), q=[90, 99.9]) \n",
    "hd.rasterize(\n",
    "    hv.Image(img_db)\n",
    ").opts(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    cmap='gray',\n",
    "    clim=(np.min(lims), np.max(lims)),\n",
    "    xlabel='Range (Near Range <--> Far Range)',\n",
    "    ylabel='Azimuth',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have a 2D sinc function corresponding to the imaged points spatial location!  \n",
    "\n",
    "We negletected system noise terms, so let's see what the image looks like with noise added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_db_with_noise = np.log10(np.abs(img_with_noise + 1e-16))\n",
    "from sarpy.visualization.remap import pedf\n",
    "hd.rasterize(\n",
    "    hv.Image(20*np.log10(img_db_with_noise))\n",
    ").opts(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    cmap='gray',\n",
    "    xlabel='Range (Near Range <--> Far Range)',\n",
    "    ylabel='Azimuth',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is that all we need to do to make an image?\n",
    "No! If we did a perfect job we would expect to see the phase of our image to be a 2D sinusoid where the range frequency describes the range position of each scatterer and the azimuth frequency describing the azimuth poisition of each scatterer.  \n",
    "\n",
    "Let's see what the sinusoid looks like for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_db = np.log10(np.abs(img))\n",
    "# lims = np.percentile(img_db.flatten(), q=[50, 99.9]) \n",
    "hd.rasterize(\n",
    "    hv.Image(np.real(cphd))\n",
    ").opts(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    cmap='gray',\n",
    "    # clim=(np.min(lims), np.max(lims)),\n",
    "    xlabel='Range',\n",
    "    ylabel='Azimuth',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the data seems to curved over azimuth instead of being constant.  This is because our data collection acutally lives on a polar grid and we have not accounted for that yet.  The act of correcting the phase such that it goes from being on a curved arc to be rectangular is known as polar formatting!  We will cover this in the next notebook!\n",
    "\n",
    "## Why did my image look good?\n",
    "* Dwell was short so there was not enough anglular disparity on the collection which means the polar grid was effectively rectilinear already\n",
    "* Point targets were constrained near the scene center point\n",
    "    - The farther out from the mocomp point you go the more variation you will see in the polar grid and the data will be less focused\n",
    "\n",
    "## What does it normally look like if you don't polar format?\n",
    "It turns out there is a product you can order for SAR data which has been matched filtered and motion compensated.  That product is known as a compensated phase history data (CPHD).  Let's see what taking a 2D FFT of a CPHD from umbra looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarpy.io.phase_history.cphd import CPHDReader\n",
    "cphd_path = '/mnt/c/Users/Austin/Documents/GitHub/radar_learning/7_basic_image_formation/2024-01-12-04-09-18_UMBRA-05_CPHD.cphd'\n",
    "reader = CPHDReader(cphd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = reader[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cphd_img = np.fft.fftshift(np.fft.fft2(ph), axes=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarpy.visualization.remap import pedf\n",
    "hd.rasterize(\n",
    "    hv.Image(pedf(cphd_img))\n",
    ").opts(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    cmap='gray',\n",
    "    # clim=(np.min(lims), np.max(lims)),\n",
    "    xlabel='Range',\n",
    "    ylabel='Azimuth',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the data looks focused near the center of the image but gets more and more blurry as you traverse farthere away from the center.  THis is because the data has not been polar formatted yet.  I won't spoil this too much but you can't take a **fast** fourier transform on data that is irregularly sampled.  Before polar formatting the data is irregularly sampled in azimuth.  The act of polar formatting is making it so that data lives on a support with even sampling so you can make use of the **fast** fourier transform\n",
    "\n",
    "## Impulse response I NEVER FINISHED THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = np.unravel_index(\n",
    "    np.argmax(img_db),\n",
    "    img_db.shape\n",
    ")\n",
    "print(peak)\n",
    "print(img_db.shape)\n",
    "mid_pulse, mid_sample = peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_ipr = img_db[mid_pulse, :].flatten()\n",
    "plt.figure()\n",
    "plt.plot(20*rg_ipr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_ipr = img_db[:, mid_sample].flatten()\n",
    "plt.figure()\n",
    "plt.plot(20*dp_ipr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
